{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"authorship_tag":"ABX9TyONJ1OpCoTBCNEUoX1a3LH6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpRCZsgOUnfz","executionInfo":{"status":"ok","timestamp":1610349719871,"user_tz":300,"elapsed":6490,"user":{"displayName":"Subha Nawer Pushpita","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIHjytx_rOqP46_t7c300pEKvxMOBeWfsQZH6MJw=s64","userId":"15148330505862032702"}},"outputId":"e57918f3-a00e-4c1e-f490-1cd99b2d9a3f"},"source":["!pip install tflearn"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tflearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n","\r\u001b[K     |███                             | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.19.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n","Building wheels for collected packages: tflearn\n","  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=de8cb5898b298d5a65164cefdd9f86919d9944431ba143ed0bc516f46fc22288\n","  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n","Successfully built tflearn\n","Installing collected packages: tflearn\n","Successfully installed tflearn-0.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbzD3luCUu3Z","executionInfo":{"status":"ok","timestamp":1610349774109,"user_tz":300,"elapsed":25187,"user":{"displayName":"Subha Nawer Pushpita","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIHjytx_rOqP46_t7c300pEKvxMOBeWfsQZH6MJw=s64","userId":"15148330505862032702"}},"outputId":"e4c2c6df-b901-4d12-bcbb-f1ef02d10537"},"source":["from google.colab import files\r\n","import os\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","os.chdir('/content/drive/My Drive/Bot_sides')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H60rSO-EUSxm","executionInfo":{"status":"ok","timestamp":1610350457769,"user_tz":300,"elapsed":1462,"user":{"displayName":"Subha Nawer Pushpita","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIHjytx_rOqP46_t7c300pEKvxMOBeWfsQZH6MJw=s64","userId":"15148330505862032702"}},"outputId":"20f15b3b-4bb0-4658-95aa-328bc4f84b48"},"source":["import nltk\r\n","nltk.download('punkt')\r\n","from nltk.stem.lancaster import LancasterStemmer\r\n","stemmer = LancasterStemmer()\r\n","\r\n","import numpy\r\n","import tflearn\r\n","import tensorflow\r\n","import random\r\n","import json\r\n","import pickle\r\n","\r\n","with open(\"intents.json\") as file:\r\n","    data = json.load(file)\r\n","\r\n","try:\r\n","    with open(\"data.pickle\", \"rb\") as f:\r\n","        words, labels, training, output = pickle.load(f)\r\n","except:\r\n","    words = []\r\n","    labels = []\r\n","    docs_x = []\r\n","    docs_y = []\r\n","\r\n","    for intent in data[\"intents\"]:\r\n","        for pattern in intent[\"patterns\"]:\r\n","            wrds = nltk.word_tokenize(pattern)\r\n","            words.extend(wrds)\r\n","            docs_x.append(wrds)\r\n","            docs_y.append(intent[\"tag\"])\r\n","\r\n","        if intent[\"tag\"] not in labels:\r\n","            labels.append(intent[\"tag\"])\r\n","\r\n","    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\r\n","    words = sorted(list(set(words)))\r\n","\r\n","    labels = sorted(labels)\r\n","\r\n","    training = []\r\n","    output = []\r\n","\r\n","    out_empty = [0 for _ in range(len(labels))]\r\n","\r\n","    for x, doc in enumerate(docs_x):\r\n","        bag = []\r\n","\r\n","        wrds = [stemmer.stem(w.lower()) for w in doc]\r\n","\r\n","        for w in words:\r\n","            if w in wrds:\r\n","                bag.append(1)\r\n","            else:\r\n","                bag.append(0)\r\n","\r\n","        output_row = out_empty[:]\r\n","        output_row[labels.index(docs_y[x])] = 1\r\n","\r\n","        training.append(bag)\r\n","        output.append(output_row)\r\n","\r\n","\r\n","    training = numpy.array(training)\r\n","    output = numpy.array(output)\r\n","\r\n","    with open(\"data.pickle\", \"wb\") as f:\r\n","        pickle.dump((words, labels, training, output), f)\r\n","\r\n","tensorflow.compat.v1.reset_default_graph()\r\n","\r\n","net = tflearn.input_data(shape=[None, len(training[0])])\r\n","net = tflearn.fully_connected(net, 8)\r\n","net = tflearn.fully_connected(net, 8)\r\n","net = tflearn.fully_connected(net,8)\r\n","net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\r\n","net = tflearn.regression(net)\r\n","\r\n","model = tflearn.DNN(net)\r\n","\r\n","try:\r\n","    model.load(\"model.tflearn\")\r\n","except:\r\n","    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\r\n","    model.save(\"model.tflearn\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Bot_sides/model.tflearn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tyymsoFuXhFi"},"source":[""],"execution_count":null,"outputs":[]}]}